---
title: ""
date: 
draft: true
---

SCIENCE
a_cycling_theory_of_scientific_process

<p>
In my wanderings of quantitative biology as a means of scientific 
inquiry, I've developed a model for how science can be done - 
or rather understood to be done after the fact.
</p>

<p>
I've translated this into advice, or directives as one sees fit,
below.
Where I can, I've desperatly tried to invoke arcane sounding 
vocabulary to lend a limited sense of authenticity, but do not let 
this mislead you from understanding this as a very modern perspective
from exposure to genomics-ish work from 2010 to 2016.
</p>

<p>
( I include an example for how this would be done to investigate the
dynamics of one particular transcript during a stereotypical 
environmental shift, using qPCR. )
</p>

<hr>

<ul>
  <li><b>First, the practitioner should construct the apparatus</b>.
  In this step, read what has been done and learn the theory of what
  you expect to happen. From this, we can develop the apparatus, or
  the tools and methodology requisite to investigate the phenomenon
  in question in a cleanly interpretable way.

  In our example, this would be the design and verification of 
  primers for qPCR, the verificaiton that culturing methodology
  and sampling are correct, that normalization and other assumptions
  seem reasonable.

  Here is a place where others can really help kick this along in
  progress, but also a place where prior work and help from others
  can bottleneck your exploration down to what is limited by prior
  assumptions. Take advantage of other's help, but dare to be 
  independent - within reason. If you're too close or too far, you
  may not see the phenomenon that explains a lot.
  </li>
  <li>
  <b>Second, explore and wander the wilderness</b>.
  By this, I mean to value breadth of exploring first before 
  hypothesis testing. Here, we fish for hypotheses to actually test.
  
  High-throughput (many samples) and broad-throughput (many variables)
  approaches are valuable here.
  Deciding the scale of what to investigate is critical, and should be
  flexible to changing. By scale, I mean the scope of investigation
  should be varied to broaden the investigation, to make sure things
  behave broadly as we expect them to, and then to narrow the use of
  limited resources to a focused point of veracity.
  More timepoints would be a reasonable focus over replicates, in
  this stage.

  In our example, I would imagine measuring our transcript of
  interest across many timepoints without replicates. We would aim
  to sketch out the interesting periods. Too infrequent of measures
  and we lose structure, too frequent and we lose time and money.
  Balance, but wander.
  </li>
  <li>
  <b>Third, formulate a model</b>.
  If you wandered well, you should have a vauge idea of the underlying
  simplified structure of the phenomenon, what causes it and how to
  think about it in a useful and compacted way. 

  If you don't, then collect all your observations, especially
  those that you have a vague intuition about, and meditate on how
  they could all fit together. 
  If this is not apparent, wander more.

  Loneliness really hurts the researcher in this, and in the next
  stage.

  In our example: 
  perhaps you observe that the cells do a particular thing, and 
  although unrelated to your phenotype of interest is similar to the
  activation of a pathway in a different kind of shift. And maybe you
  wonder if this particular signalling pathway is active during your
  transition and may be involved in your phenotype. 
  Perhaps you're interested in it's involvement in a particular 
  change in rates of some dynamics.
  </li>
  <li>
  <b>Fourth, test the model</b>.
  This is the easiest part, and is the one most folks think of
  as the scientific process.

  Having done all the hard work of proposing a model, or more usefully
  a series of models, you should be able to propose a way to make a
  pertubation to some element of the model. This must in some way
  generate a measureable output that would be consistent or 
  inconsistent with your model.
  Then, perturb the system and see if the output matches your 
  prediction. The methodology of the pertubation may require a return
  to step one.

  Think of this as an excercise of usefulness of the model, ie is
  this condensed representation of what you think of going on useful?
  Personally, I'm agnostic to the imeplementation of the model so
  long as it is useful. Voodoo may be phenomenological, but if it
  has predictive power than the model must be evaluated on that 
  criteria.
  What is its explanatory power?

  Having disrupted some pathway of interest, do the dynamics change
  as expected?
  </li>
  <li>
  <b>Fifth, compress and communicate the model</b>.
  This is an essential skill that has eluded me for quite some time,
  or rather I eluded it through procrastination and foolish
  prioritization.

  Write and talk to people about your model and the evidence for it.
  You must get feedback from your peers and comrades in the 
  investigatory field.

  In our example, presenting the work necessitates the investigator
  determines that the pathway is or is not involved in the changes in
  dynamics of the transcript, or the like. Here is where other 
  investigators may share unpublished observations, other 
  interpretations, or other supporting or critical commentary.
  This feedback is precious and scarce.
  </li>
</ul>

<hr>

<p>
Reconciling models that have various extents of explanatory power
will likely require additional testing. Gaps that cannot be filled
will need more wandering and thinking. Eventually, many models can
be simplified together.
</p>

<p>
Each simplification that keeps its predictive value is a powerful
focusing that does not detract from what is learned but rather spreads 
the distillation of it around the world.
</p>

<p>
Hyperbole, hyperbole, I hope that was useful.
</p>

